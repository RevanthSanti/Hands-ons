{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mgujAhsQt8xn"
      },
      "outputs": [],
      "source": [
        "!wget https://raw.githubusercontent.com/bigmlcom/python/master/data/spam.csv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('spam.csv' , encoding = 'utf-8' , sep = \"\\t\")\n",
        "df.head()"
      ],
      "metadata": {
        "id": "lUq4NKds0jR3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "ULX0Nnz52Lhw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "round(df['Type'].value_counts(normalize = True)*100,2)"
      ],
      "metadata": {
        "id": "0Y1YLENZ0x4p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"length\"] = df[\"Message\"].apply(len)"
      ],
      "metadata": {
        "id": "Zb8N17cD1ed9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "HE95X_vN2HUV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Visulization"
      ],
      "metadata": {
        "id": "vzs4SLX728JF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "4X55ZUQ02zol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df['length'].plot.hist(bins = 50)\n",
        "df['length'].plot(kind = 'hist' , bins = 50)"
      ],
      "metadata": {
        "id": "4UHLst_k3EWF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Type'].unique()"
      ],
      "metadata": {
        "id": "rgkK2IeE3JUe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[df['Type']== 'ham']['length'].plot(kind = 'hist' , bins = 50 , alpha = 0.5 , color = 'green' , label = 'ham messages')\n",
        "df[df['Type']== 'spam']['length'].plot(kind = 'hist' , bins = 50 , alpha = 0.5 , color = 'blue' , label = 'spam messages')"
      ],
      "metadata": {
        "id": "YTJgKkRW3fJe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for messages in df['Message']:\n",
        "  print(messages)"
      ],
      "metadata": {
        "id": "G6gjcZ284DS2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problems in message col:\n",
        "\n",
        " - Not a fix format\n",
        " - Spelling problems  - Because spelling problem , we need advanced models e.g. Glove , Elmo , BERT , Roberta , Good amount of dictionary, Spelling correction models.\n",
        " - Special characters\n",
        " - Upper case issues"
      ],
      "metadata": {
        "id": "u57z8-Rx6Nqi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "mess = \"This is sample messaging!@..\""
      ],
      "metadata": {
        "id": "FqVuV3JC5Vgq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mess"
      ],
      "metadata": {
        "id": "1xq3APhR7DOk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nonpunc = ''.join([char for char in mess if char not in string.punctuation])"
      ],
      "metadata": {
        "id": "038Ig_7F7ES_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nonpunc"
      ],
      "metadata": {
        "id": "17WWZgJ-8JJl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "id": "QSRa1Fy57fDa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "stopwords.words('english')"
      ],
      "metadata": {
        "id": "RZ4QiUL_79LT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_mess = [word for word in nonpunc.split() if word.lower() not in stopwords.words('english')]"
      ],
      "metadata": {
        "id": "fmkNocMn8lkT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_mess"
      ],
      "metadata": {
        "id": "NSk4IIoH804S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Text Process\n",
        "def text_preprocess(mess):\n",
        "  nonpunc = ''.join([char for char in mess if char not in string.punctuation])\n",
        "  clean_mess = [word for word in nonpunc.split() if word.lower() not in stopwords.words('english')]\n",
        "  return clean_mess"
      ],
      "metadata": {
        "id": "FE9zZBJX9Nq-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['word_processed'] = df['Message'].apply(text_preprocess)"
      ],
      "metadata": {
        "id": "Tkqjd7fm9vq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['word_processed']"
      ],
      "metadata": {
        "id": "Du46QJIc9-Az"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "GzriFnWZ-DB7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['word_processed'].value_counts()[:10].plot(kind = 'bar')"
      ],
      "metadata": {
        "id": "B5Ked9XU-Ihn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#How to find most common words in SPAM messages\n",
        "df[df['Type']=='spam']['word_processed'].value_counts()[:10]"
      ],
      "metadata": {
        "id": "qaGVAiwR-Nl_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[df['Type']=='ham']['word_processed'].value_counts()[:10]"
      ],
      "metadata": {
        "id": "PgxS6sV0_QHg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "metadata": {
        "id": "5kodRUPJ_1vI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bow_transformer = CountVectorizer(analyzer = text_preprocess).fit(df['Message'])"
      ],
      "metadata": {
        "id": "qaFg-L2wEoOM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(bow_transformer.vocabulary_)"
      ],
      "metadata": {
        "id": "9g4EqlygEyvw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_03 = df['Message'][3]"
      ],
      "metadata": {
        "id": "mXtv8OsYE3ss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_03"
      ],
      "metadata": {
        "id": "wjzvR-1nFJSl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bow_03 = bow_transformer.transform([df_03])\n",
        "print(df_03)\n",
        "print(\"============\")\n",
        "print(bow_03)\n",
        "print(\"===============\")\n",
        "print(bow_03.shape)"
      ],
      "metadata": {
        "id": "HUCWdrykFKdV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_03)\n",
        "print(\"============\")\n",
        "print(bow_transformer.get_feature_names_out()[873])\n",
        "print(\"============\")\n",
        "print(bow_transformer.get_feature_names_out()[2320])"
      ],
      "metadata": {
        "id": "Vg7QAr5XFWS4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_bow = bow_transformer.transform(df['Message'])"
      ],
      "metadata": {
        "id": "edHGZgf3FXpo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_bow.shape"
      ],
      "metadata": {
        "id": "nAZehoU4GoZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_bow.nnz)"
      ],
      "metadata": {
        "id": "y4qtfH6eGrUd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sparsity = round((100.0*df_bow.nnz/(df_bow.shape[0]*df_bow.shape[1])),3)"
      ],
      "metadata": {
        "id": "kO_eAEnXGx7V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer"
      ],
      "metadata": {
        "id": "jPZo2gSzHETx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_transformer = TfidfTransformer().fit(df_bow)"
      ],
      "metadata": {
        "id": "3_xZC4keHUHh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_03 = tfidf_transformer.transform(bow_03)"
      ],
      "metadata": {
        "id": "3oEdmuBGHdf9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tfidf_03)"
      ],
      "metadata": {
        "id": "_Ufik8TtHl4w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tfidf_transformer.idf_[bow_transformer.vocabulary_['U']])\n",
        "print(tfidf_transformer.idf_[bow_transformer.vocabulary_['say']])\n",
        "print(tfidf_transformer.idf_[bow_transformer.vocabulary_['already']])\n",
        "print(tfidf_transformer.idf_[bow_transformer.vocabulary_['early']])"
      ],
      "metadata": {
        "id": "0kf-JmqMHo01"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_tfidf = tfidf_transformer.transform(df_bow)"
      ],
      "metadata": {
        "id": "nplXfWX5I9vd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_tfidf.shape)"
      ],
      "metadata": {
        "id": "Tbevs5NDJPAx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TRain the model"
      ],
      "metadata": {
        "id": "L7afxzazJT4w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB"
      ],
      "metadata": {
        "id": "bIN2ZcQKJRFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spam_detect_model = MultinomialNB().fit(df_tfidf , df['Type'])"
      ],
      "metadata": {
        "id": "Cmhh3nzPJceN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"predicted-\" , spam_detect_model.predict(tfidf_03)[0])\n",
        "print(\"actual-\" , df.Type[3])"
      ],
      "metadata": {
        "id": "byIoaqKXJmOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_predictions = spam_detect_model.predict(df_tfidf)"
      ],
      "metadata": {
        "id": "8XMrNwkXJuB6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_predictions"
      ],
      "metadata": {
        "id": "jaARtwGMJ9yu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "sms_train , sms_test , label_train , label_test = train_test_split(df['Message'] , df['Type'] , test_size = 0.4)"
      ],
      "metadata": {
        "id": "NgkeFg2FJ_fG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Shape of SMS Train Data\" , sms_train.shape)\n",
        "print(\"Shape of SMS Label Train Data\" , label_train.shape)\n",
        "print(\"Shape of SMS Test Data\" , sms_test.shape)\n",
        "print(\"Shape of SMS label test Data\" , label_test.shape)\n"
      ],
      "metadata": {
        "id": "VTYQl4DiKVdv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline"
      ],
      "metadata": {
        "id": "yw2ZrpRSKp0u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = Pipeline([\n",
        "    ('bow' , CountVectorizer(analyzer = text_preprocess)),\n",
        "    ('tfidf' , TfidfTransformer()),\n",
        "    ('classifier' , MultinomialNB())\n",
        "])"
      ],
      "metadata": {
        "id": "z9v-HX55KvFK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline.fit(sms_train , label_train)"
      ],
      "metadata": {
        "id": "VefLSDnrLAmS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = pipeline.predict(sms_test)"
      ],
      "metadata": {
        "id": "zq0g8wE4LGl2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next_text = [\"During our last conversation we agreed to deliver goods\" ,\n",
        "             \"you have been selected to receive 10000 cash prize\"]\n",
        "\n",
        "predictions_01 = pipeline.predict(next_text)\n",
        "print(predictions_01)"
      ],
      "metadata": {
        "id": "kW1W4vIULMhR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AseJSHC8Ll3G"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}